{"cells":[{"metadata":{},"cell_type":"markdown","source":"#   *Carregando as bibliotecas*"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n\n# Disable warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Import plotting modules\n!pip install chart_studio\nimport seaborn as sns\nsns.set()\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker\nimport plotly.express as px\nfrom plotly.offline import iplot\n\nimport chart_studio.plotly as py\nimport plotly.graph_objs as go\nimport cufflinks\ncufflinks.go_offline()\ncufflinks.set_config_file(world_readable=True, theme='pearl')\n%matplotlib inline\n\nwarnings.filterwarnings(\"ignore\")\nimport plotly.figure_factory as ff\nfrom colorama import Fore, Back, Style \n\n# Import machine learning algorithms\nimport xgboost\nimport lightgbm\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set_context(\n    \"notebook\", \n    font_scale=1.5,       \n    rc={ \n        \"figure.figsize\": (11, 8), \n        \"axes.titlesize\": 18 \n    }\n)\n\nfrom matplotlib import rcParams\nrcParams['figure.figsize'] = 11, 8","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Load dataset**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/mlcourse/mlbootcamp5_train.csv\")\nprint(\"dataset size: \", df.shape)\ndf.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Drop column id**"},{"metadata":{"trusted":true},"cell_type":"code","source":"dff = df.drop(\"id\", axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dff.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dff['gluc']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Contando e agrupando as features "},{"metadata":{"trusted":true},"cell_type":"code","source":"df_uniques = pd.melt(frame=dff, value_vars=['gender','cholesterol', \n                                           'gluc', 'smoke', 'alco', \n                                           'active', 'cardio'])\ndf_uniques = pd.DataFrame(df_uniques.groupby(['variable', \n                                              'value'])['value'].count()) \\\n    .sort_index(level=[0, 1]) \\\n    .rename(columns={'value': 'count'}) \\\n    .reset_index()\n\nsns.factorplot(x='variable', y='count', hue='value', \n               data=df_uniques, kind='bar', size=12);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Com base nos gráfics acima, as features  apresentam um considerável desbalanceamento. Vemos que a maioria dos indivíduos praticam atividades física, não consomem álcool regularmente, apresentam níveis normais de glicóse e os não fumantes também são prevalecentes. Contudo, a quantidade de cardios e não cardios são bem balanceados.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_uniques = pd.melt(frame=dff, value_vars=['gender','cholesterol', \n                                           'gluc', 'smoke', 'alco', \n                                           'active'], \n                     id_vars=['cardio'])\ndf_uniques = pd.DataFrame(df_uniques.groupby(['variable', 'value', \n                                              'cardio'])['value'].count()) \\\n    .sort_index(level=[0, 1]) \\\n    .rename(columns={'value': 'count'}) \\\n    .reset_index()\n\nsns.factorplot(x='variable', y='count', hue='value', \n               col='cardio', data=df_uniques, kind='bar', size=9);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**No gráfico acima ao compararmos as features dos cardios e não cardios, vemos que a quantidade de indivíduos com níveis mais elevados de colesterol, glicose e sendentárismo são maiores do que a quantidade de indivíduos não cardios, sendo estes os fatores mais relevantes. Surpreendetemente, não há muita difença entre os níveis de consulmo de álcool e fumantes quando comparamos os indíduos cardios com os não cardios. Isso pode estar relacinado com baixa quantidade de índividos com essas características quando comparamos a quantidade total de indíduos.**"},{"metadata":{},"cell_type":"markdown","source":"# Others factors hist plots"},{"metadata":{"trusted":true},"cell_type":"code","source":"dff['age'].iplot(kind='hist',\n                              xTitle='Idade(Dias)', \n                              yTitle='Quantidade',\n                              linecolor='black', \n                              opacity=0.7,\n                              color='#FB8072',\n                              theme='pearl',\n                              bargap=0.2,\n                              gridcolor='white',\n                              title='Distribuição das idades')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.histogram(dff, x=\"age\", color=\"cardio\", marginal=\"violin\", hover_data=dff.columns)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Nesse gráfico vemos a distribuição da quantidade de índividos  não cardios e cardios com relação a idade. Como é de se esperar, a quantidade de indívidos cardios cresce a medida que a quantidade invíduos saudávies vai diminuindo com o avançado da idade. "},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.scatter(dff, x=\"weight\", y=\"age\", color='cardio')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Fica claro que existe um relação direta entre idade e sobrepeso com relação aos índivíduos com algum problema cardíaco.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.scatter(dff, x=\"height\", y=\"age\", color='cardio')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**A distribuição de idades com as alturas, como mostra o gráfico, são relativamente homogêneas. Parecendo que há uma região com ínvíduos com idade entre 14mil e 16mil dias (~38 anos e ~44 anos) com alturas aproximadas entre 1.45m e 1.74m.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.scatter(dff, x=\"ap_hi\", y=\"age\", color='cardio')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corrmat = dff.corr() \nf, ax = plt.subplots(figsize =(12, 10)) \nsns.heatmap(corrmat, ax = ax, cmap = 'RdYlBu_r', linewidths = 0.5) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Aplicando modelos de predição."},{"metadata":{},"cell_type":"markdown","source":"**Usaremos modelos de machine larning para prevermos qual a probalidade de um indivídou com base em suas features venha a ser tornar cardio ou não.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Separando as labels e variáveis alvo.\ny = dff[\"cardio\"]\nx = dff.drop(\"cardio\", axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_list = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Decision Tree Classifier\n\ndt_clf = DecisionTreeClassifier(max_leaf_nodes=10, random_state=30, criterion='entropy')\ndt_clf.fit(x_train, y_train)\ndt_pred = dt_clf.predict(x_test)\ndt_acc = dt_clf.score(x_test,y_test)\naccuracy_list.append(100*dt_acc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(Fore.GREEN + \"Accuracy of Decision Tree Classifier is : \", \"{:.2f}%\".format(100* dt_acc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nmat = confusion_matrix(y_test, dt_pred)\nsns.heatmap(mat.T, square=True, annot=True,fmt=\"d\", cbar = False)\nplt.title(\"Tree Clasifier - Confusion Matrix\")\nplt.xticks(range(2), [\"Heart Not Disease\",\"Heart Disease\"], fontsize=16)\nplt.yticks(range(2), [\"Heart Not Disease\",\"Heart Disease\"], fontsize=16)\nplt.xlabel(\"true label\")\nplt.ylabel(\"predicted label\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# K Neighbors Classifier\n\nkn_clf = KNeighborsClassifier(n_neighbors=6)\nkn_clf.fit(x_train, y_train)\nkn_pred = kn_clf.predict(x_test)\nkn_acc = kn_clf.score(x_test,y_test)\naccuracy_list.append(100*kn_acc)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(Fore.GREEN + \"Accuracy of K Neighbors Classifier is : \", \"{:.2f}%\".format(100* kn_acc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nmat = confusion_matrix(y_test, kn_pred)\nsns.heatmap(mat.T, square=True, annot=True,fmt=\"d\", cbar = False)\nplt.xlabel(\"true label\")\nplt.ylabel(\"predicted label\")\nplt.title(\"K Neighbors Classifier - Confusion Matrix\")\nplt.xticks(range(2), [\"Heart Not Disease\",\"Heart Disease\"], fontsize=16)\nplt.yticks(range(2), [\"Heart Not Disease\",\"Heart Disease\"], fontsize=16);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# RandomForestClassifier\nr_clf = RandomForestClassifier(max_features=0.5, max_depth=15, random_state=1)\nr_clf.fit(x_train, y_train)\nr_pred = r_clf.predict(x_test)\nr_acc = r_clf.score(x_test,y_test)\naccuracy_list.append(100*r_acc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(Fore.GREEN + \"Accuracy of Random Forest Classifier is : \", \"{:.2f}%\".format(100* r_acc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nmat = confusion_matrix(y_test, r_pred)\nsns.heatmap(mat.T, square=True, annot=True,fmt=\"d\", cbar = False)\nplt.xlabel(\"true label\")\nplt.ylabel(\"predicted label\")\nplt.title(\"Random Forest Classifier - Confusion Matrix\")\nplt.xticks(range(2), [\"Heart Not Disease\",\"Heart Disease\"], fontsize=16)\nplt.yticks(range(2), [\"Heart Not Disease\",\"Heart Disease\"], fontsize=16);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# GradientBoostingClassifier\n\ngradientboost_clf = GradientBoostingClassifier(max_depth=2, random_state=4)\ngradientboost_clf.fit(x_train,y_train)\ngradientboost_pred = gradientboost_clf.predict(x_test)\ngradientboost_acc = gradientboost_clf.score(x_test,y_test)\naccuracy_list.append(100*gradientboost_acc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(Fore.GREEN + \"Accuracy of Gradient Boosting is : \", \"{:.2f}%\".format(100* gradientboost_acc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nmat = confusion_matrix(y_test, gradientboost_pred)\nsns.heatmap(mat.T, square=True, annot=True,fmt=\"d\", cbar = False)\nplt.xlabel(\"true label\")\nplt.ylabel(\"predicted label\")\nplt.title(\"Random Forest Classifier - Confusion Matrix\")\nplt.xticks(range(2), [\"Heart Not Disease\",\"Heart Disease\"], fontsize=16)\nplt.yticks(range(2), [\"Heart Not Disease\",\"Heart Disease\"], fontsize=16);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_list = ['DecisionTree', 'KNearestNeighbours', 'RandomForest', 'GradientBooster']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize']=20,8\nsns.set_style('darkgrid')\nax = sns.barplot(x=model_list, y=accuracy_list, palette = \"vlag\", saturation =2.0)\nplt.xlabel('Classifier Models', fontsize = 20 )\nplt.ylabel('% of Accuracy', fontsize = 20)\nplt.title('Accuracy of different Classifier Models', fontsize = 20)\nplt.xticks(fontsize = 12, horizontalalignment = 'center', rotation = 8)\nplt.yticks(fontsize = 12)\nfor i in ax.patches:\n    width, height = i.get_width(), i.get_height()\n    x, y = i.get_xy() \n    ax.annotate(f'{round(height,2)}%', (x + width/2, y + height*1.02), ha='center', fontsize = 'x-large')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Testamos quatro modelos de machine learning, Decision Tree, KNearest Neighbours, Random Forest e Gradient Booster. Como compilado no gráfico acima, o Gradient Booster se provou ser o melhor modelo de previsão para os nossos dados. Embora, com exceção do modelo KNearest Neighbour todos os outros apresentam acuracia semelhante.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot( y= dff['age'] )","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}